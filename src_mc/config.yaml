mc:
  chunk_tokens: 128
  overlap_tokens: 20
  retriever_topk: 4  # 推理阶段保留的历史证据数
  retriever_search_k: 16  # 初始召回上限，建议为 topk 的 3-5 倍
  use_faiss: true
  index_path: ./indexes/mc/faiss.index
  store_path: ./indexes/mc/store.jsonl
  embed_model: BAAI/bge-m3
  normalize: true

llm:
  endpoint: http://127.0.0.1:8000/v1/chat/completions
  model: /data/zhangjingwei/LL-Doctor-qwen3-8b-Model
  max_new_tokens: 30000
  temperature: 0.7
  top_p: 0.95
  concurrent_requests: 6

self_judge:
  enable: true
  min_pass_score: 3.5
  max_refine: 1
